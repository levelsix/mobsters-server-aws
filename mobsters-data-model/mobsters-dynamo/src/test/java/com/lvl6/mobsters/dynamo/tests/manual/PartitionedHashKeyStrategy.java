package com.lvl6.mobsters.dynamo.tests.manual;

import java.util.ArrayList;
import java.util.Date;
import java.util.List;
import java.util.UUID;
import java.util.concurrent.Callable;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.Future;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.beans.factory.annotation.Qualifier;
import org.springframework.stereotype.Component;

import com.amazonaws.services.dynamodbv2.datamodeling.DynamoDBAttribute;
import com.amazonaws.services.dynamodbv2.datamodeling.DynamoDBAutoGeneratedKey;
import com.amazonaws.services.dynamodbv2.datamodeling.DynamoDBHashKey;
import com.amazonaws.services.dynamodbv2.datamodeling.DynamoDBQueryExpression;
import com.amazonaws.services.dynamodbv2.datamodeling.DynamoDBRangeKey;
import com.amazonaws.services.dynamodbv2.datamodeling.DynamoDBTable;
import com.amazonaws.services.dynamodbv2.datamodeling.DynamoDBVersionAttribute;
import com.amazonaws.services.dynamodbv2.datamodeling.PaginatedQueryList;
import com.amazonaws.services.dynamodbv2.model.AttributeValue;
import com.amazonaws.services.dynamodbv2.model.ComparisonOperator;
import com.amazonaws.services.dynamodbv2.model.Condition;
import com.amazonaws.services.dynamodbv2.transactions.Transaction;
import com.amazonaws.services.dynamodbv2.transactions.Transaction.IsolationLevel;
import com.google.common.base.Function;
import com.google.common.collect.FluentIterable;
import com.google.common.collect.Iterables;
import com.lvl6.mobsters.dynamo.setup.Lvl6Transaction;
import com.lvl6.mobsters.dynamo.tests.manual.PartitionedHashKeyStrategy.ChildTwo;
import com.lvl6.mobsters.dynamo.tests.manual.PartitionedHashKeyStrategy.ParentTwo;

/**
 * Strategy class that exercises
 * 
 * @author John
 */
@Component
@Qualifier("VariantTwo")
public class PartitionedHashKeyStrategy implements VariantStrategy<ParentTwo, ChildTwo>
{
	@Autowired
	PartitionedHashStrategy pcRepo;

	private String currentParentHashKey = null;
	private ParentTwo currentParent = null;
	private final ArrayList<ChildTwo> currentChildren = new ArrayList<ChildTwo>(0);

	@Override
	public String getNextParent( final int expectedChildCount )
	{
		currentChildren.clear();
		currentChildren.ensureCapacity(expectedChildCount);

		currentParent = new ParentTwo();
		currentParent.setName("Eddie");
		pcRepo.saveParent(currentParent);

		currentParentHashKey = currentParent.getId();
		return currentParentHashKey;
	}

	@Override
	public BaseParentChildRepository<ParentTwo, ChildTwo> getRepository()
	{
		return pcRepo;
	}

	@Override
	public ChildDataAttrs addNextChild()
	{
		final ChildTwo retVal = new ChildTwo();
		currentChildren.add(retVal);
		return retVal;
	}

	@Override
	public void saveChildren()
	{
		pcRepo.saveChildren(currentParentHashKey, currentChildren);
		currentParentHashKey = null;
		currentChildren.clear();
	}

	@DynamoDBTable(tableName = "ParentTwo")
	public static class ParentTwo
	{
		@DynamoDBAutoGeneratedKey
		@DynamoDBHashKey(attributeName = "id")
		private String id;

		@DynamoDBVersionAttribute
		private Long version;

		@DynamoDBAttribute(attributeName = "name")
		private String name;

		public ParentTwo()
		{
			super();
		}

		public ParentTwo( final String id /* , String name */)
		{
			super();

			this.id = id;
			// this.name = name;
		}

		public String getId()
		{
			return id;
		}

		/**
		 * Replaces this object's id attribute with a new caller-provided
		 * value..
		 * 
		 * The semantics of this operation, especially in terms of the large
		 * universe of "other" objects, is not terribly well defined. There may
		 * be entity types that are highly intollerant of their Id changing
		 * during the course of their existence, as Id storage is the means of
		 * creating links between a visible object and any other object that
		 * depends on it by reference.
		 * 
		 * @param id
		 */
		public void setId( final String id )
		{
			this.id = id;
		}

		public Long getVersion()
		{
			return version;
		}

		public void setVersion( final Long version )
		{
			this.version = version;
		}

		public String getName()
		{
			return name;
		}

		public void setName( final String name )
		{
			this.name = name;
		}
	}

	@DynamoDBTable(tableName = "ChildTwo")
	public static class ChildTwo extends ChildDataAttrs
	{
		private String userId;

		private String id;
		private Long version;

		public ChildTwo()
		{
			super();
		}

		public ChildTwo( final String userId, final String id, final String name,
		    final int monsterId, final int currentExp, final int currentLvl,
		    final int currentHealth, final int numPieces, final boolean isComplete,
		    final Date combineStartTime, final int teamSlotNum, final String sourceOfPieces,
		    final double tradeValue )
		{
			super(name, monsterId, currentExp, currentLvl, currentHealth, numPieces,
			    isComplete, combineStartTime, teamSlotNum, sourceOfPieces, tradeValue);
			this.userId = userId;
			this.id = id;
		}

		@DynamoDBAutoGeneratedKey
		@DynamoDBRangeKey(attributeName = "id")
		public String getId()
		{
			return id;
		}

		public void setId( final String id )
		{
			this.id = id;
		}

		@DynamoDBVersionAttribute
		public Long getVersion()
		{
			return version;
		}

		public void setVersion( final Long version )
		{
			this.version = version;
		}

		@DynamoDBHashKey(attributeName = "userId")
		public String getUserId()
		{
			return userId;
		}

		public void setUserId( final String userId )
		{
			this.userId = userId;
		}

		@Override
		@DynamoDBAttribute(attributeName = "name")
		public String getName()
		{
			return super.getName();
		}

		@Override
		public void setName( final String name )
		{
			super.setName(name);
		}

		@Override
		@DynamoDBAttribute(attributeName = "monsterId")
		public int getMonsterId()
		{
			return super.getMonsterId();
		}

		@Override
		public void setMonsterId( final int monsterId )
		{
			super.setMonsterId(monsterId);
		}

		@Override
		@DynamoDBAttribute(attributeName = "currentExp")
		public int getCurrentExp()
		{
			return super.getCurrentExp();
		}

		@Override
		public void setCurrentExp( final int currentExp )
		{
			super.setCurrentExp(currentExp);
		}

		@Override
		@DynamoDBAttribute(attributeName = "currentLvl")
		public int getCurrentLvl()
		{
			return super.getCurrentLvl();
		}

		@Override
		public void setCurrentLvl( final int currentLvl )
		{
			super.setCurrentLvl(currentLvl);
		}

		@Override
		@DynamoDBAttribute(attributeName = "currentHealth")
		public int getCurrentHealth()
		{
			return super.getCurrentHealth();
		}

		@Override
		public void setCurrentHealth( final int currentHealth )
		{
			super.setCurrentHealth(currentHealth);
		}

		@Override
		@DynamoDBAttribute(attributeName = "numPieces")
		public int getNumPieces()
		{
			return super.getNumPieces();
		}

		@Override
		public void setNumPieces( final int numPieces )
		{
			super.setNumPieces(numPieces);
		}

		@Override
		@DynamoDBAttribute(attributeName = "complete")
		public boolean isComplete()
		{
			return super.isComplete();
		}

		@Override
		public void setComplete( final boolean isComplete )
		{
			super.setComplete(isComplete);
		}

		@Override
		@DynamoDBAttribute(attributeName = "combineStartTime")
		public Date getCombineStartTime()
		{
			return super.getCombineStartTime();
		}

		@Override
		public void setCombineStartTime( final Date combineStartTime )
		{
			super.setCombineStartTime(combineStartTime);
		}

		@Override
		@DynamoDBAttribute(attributeName = "teamSlotNum")
		public int getTeamSlotNum()
		{
			return super.getTeamSlotNum();
		}

		@Override
		public void setTeamSlotNum( final int teamSlotNum )
		{
			super.setTeamSlotNum(teamSlotNum);
		}

		@Override
		@DynamoDBAttribute(attributeName = "sourceOfPieces")
		public String getSourceOfPieces()
		{
			return super.getSourceOfPieces();
		}

		@Override
		public void setSourceOfPieces( final String sourceOfPieces )
		{
			super.setSourceOfPieces(sourceOfPieces);
		}

		@Override
		@DynamoDBAttribute(attributeName = "tradeInValue")
		public double getTradeInValue()
		{
			return super.getTradeInValue();
		}

		@Override
		public void setTradeInValue( final double tradeInValue )
		{
			super.setTradeInValue(tradeInValue);
		}

		@Override
		public int hashCode()
		{
			final int prime = 31;
			int result = 1;
			result = (prime * result)
			    + ((id == null) ? 0 : id.hashCode());
			result = (prime * result)
			    + ((userId == null) ? 0 : userId.hashCode());
			return result;
		}

		@Override
		public boolean equals( final Object obj )
		{
			if (this == obj) {
				return true;
			}
			if (obj == null) {
				return false;
			}
			if (getClass() != obj.getClass()) {
				return false;
			}
			final ChildTwo other = (ChildTwo) obj;
			if (id == null) {
				if (other.id != null) {
					return false;
				}
			} else if (!id.equals(other.id)) {
				return false;
			}
			if (userId == null) {
				if (other.userId != null) {
					return false;
				}
			} else if (!userId.equals(other.userId)) {
				return false;
			}
			return true;
		}
	}

	@Qualifier("VariantTwo")
	@Component
	public static class PartitionedHashStrategy extends
	    BaseParentChildRepository<ParentTwo, ChildTwo>
	{
		@SuppressWarnings("unused")
		private static Logger LOG = LoggerFactory.getLogger(PartitionedHashStrategy.class);
		private final int numParts;
		private final ExecutorService threadPool = Executors.newCachedThreadPool();

		public PartitionedHashStrategy()
		{
			super(ParentTwo.class, ChildTwo.class);
			numParts = 4;
		}

		public PartitionedHashStrategy( final int numParts )
		{
			super(ParentTwo.class, ChildTwo.class);
			this.numParts = numParts;
		}

		@Override
		public void saveParent( final ParentTwo obj )
		{
			final Lvl6Transaction t1 = repoTxManager.getActiveTransaction();
			if (t1 != null) {
				t1.save(obj);
			} else {
				mapper.save(obj);
			}
		}

		@Override
		public ParentTwo loadParent( final String hashKey )
		{
			final Lvl6Transaction t1 = repoTxManager.getActiveTransaction();
			ParentTwo retVal;
			if (t1 != null) {
				retVal = t1.load(pClass, hashKey);
			} else {
				retVal = repoTxManager.load(pClass, hashKey, IsolationLevel.COMMITTED);
			}

			return retVal;
		}

		@Override
		public void deleteParent( final ParentTwo item )
		{
			// TODO: Clean up the child table as well!

			final Lvl6Transaction t1 = repoTxManager.getActiveTransaction();
			if (t1 != null) {
				t1.delete(item);
			} else {
				mapper.delete(item);
			}
		}

		@Override
		public void saveChild( final String parentHashKey, final ChildTwo obj )
		{
			setPartitionedKey(parentHashKey, obj);
			final Transaction t1 = repoTxManager.getActiveTransaction();
			if (t1 != null) {
				t1.save(obj);
			} else {
				mapper.save(obj);
			}
		}

		@Override
		public void saveChildren( final String parentHashKey, final Iterable<ChildTwo> children )
		{
			final Transaction t1 = repoTxManager.getActiveTransaction();
			if (t1 != null) {
				for (final ChildTwo obj : children) {
					setPartitionedKey(parentHashKey, obj);
					t1.save(obj);
				}
			} else {
				for (final ChildTwo obj : children) {
					setPartitionedKey(parentHashKey, obj);
					mapper.save(obj);
				}
			}
		}

		@Override
		public ChildTwo loadChild( final String parentHashKey, final String childRangeKey )
		{
			final Lvl6Transaction t1 = repoTxManager.getActiveTransaction();
			final String partitionedHashKey =
			    getPartitionedHashKey(parentHashKey, childRangeKey);
			final ChildTwo retVal;
			if (t1 != null) {
				retVal = t1.load(cClass, partitionedHashKey, childRangeKey);
			} else {
				retVal =
				    repoTxManager.load(cClass, partitionedHashKey, childRangeKey,
				        IsolationLevel.COMMITTED);
			}

			return retVal;
		}

		@Override
		public List<ChildTwo> loadChildren( final String parentHashKey,
		    final Iterable<String> childRangeKeys )
		{
			final Lvl6Transaction t1 = repoTxManager.getActiveTransaction();
			final ArrayList<ChildTwo> retVal = new ArrayList<>();
			if (t1 != null) {
				for (final String childRangeKey : childRangeKeys) {
					final String partitionedHashKey =
					    getPartitionedHashKey(parentHashKey, childRangeKey);
					retVal.add(t1.load(cClass, partitionedHashKey, childRangeKey));
				}
			} else {
				for (final String childRangeKey : childRangeKeys) {
					final String partitionedHashKey =
					    getPartitionedHashKey(parentHashKey, childRangeKey);
					retVal.add(repoTxManager.load(cClass, partitionedHashKey, childRangeKey,
					    IsolationLevel.COMMITTED));
				}
			}

			return retVal;
		}

		/**
		 * With this implementation, there is no way to achieve a transactional
		 * read because the Query API is not offered and there is no way to
		 * identify the set of records to read without it since no such list is
		 * maintained in object state.
		 * 
		 * TODO: If query() is synchronous in nature, it may be necessary to use
		 * an executor service and join on all results returning.
		 */
		@Override
		public List<ChildTwo> loadAllChildren( final String parentHashKey )
		{
			final ArrayList<Future<PaginatedQueryList<ChildTwo>>> retValSource =
			    new ArrayList<>();
			for (int ii = 0; ii < numParts; ii++) {
				// Construct the hash key outside the task so we have ii
				// embedded into a final field.
				final String partitionedHashKey = parentHashKey
				    + ':'
				    + ii;

				// Use the thread pool so all N work units are concurrent.
				retValSource.add(threadPool.submit(new Callable<PaginatedQueryList<ChildTwo>>() {
					@Override
					public PaginatedQueryList<ChildTwo> call()
					{
						final ChildTwo hashKey = new ChildTwo();
						hashKey.setUserId(partitionedHashKey);
						final DynamoDBQueryExpression<ChildTwo> query =
						    new DynamoDBQueryExpression<ChildTwo>().withHashKeyValues(hashKey)
						        .withRangeKeyCondition(
						            "id",
						            new Condition().withComparisonOperator(
						                ComparisonOperator.LT)
						                .withAttributeValueList(new AttributeValue("z")))
						        .withConsistentRead(true);
						// LOG.info("Query: {}", query.toString());
						final PaginatedQueryList<ChildTwo> retVal = childQuery(query);
						retVal.loadAllResults();
						return retVal;
					}
				}));
			}

			// WAit until all Futures have resolved.
			return FluentIterable.from(
			    Iterables.concat(FluentIterable.from(retValSource)
			        .transform(
			            new Function<Future<PaginatedQueryList<ChildTwo>>, PaginatedQueryList<ChildTwo>>() {
				            @Override
				            public PaginatedQueryList<ChildTwo> apply(
				                final Future<PaginatedQueryList<ChildTwo>> source )
				            {
					            PaginatedQueryList<ChildTwo> retVal;
					            try {
						            retVal = source.get();
					            } catch (final InterruptedException e) {
						            throw new RuntimeException(e);
					            } catch (final ExecutionException e) {
						            throw new RuntimeException(e);
					            }
					            retVal.loadAllResults();
					            return retVal;
				            }
			            })))
			    .toImmutableList();
		}

		private static Function<ChildTwo, String> CHILD_TO_ID_FUNCTION =
		    new Function<ChildTwo, String>() {
			    @Override
			    public String apply( final ChildTwo input )
			    {
				    return input.getId();
			    }
		    };

		@Override
		public List<String> getAllChildren( final String parentHashKey )
		{
			return convertToIds(loadAllChildren(parentHashKey));
		}

		@Override
		public void deleteChild( final String parentHashKey, final ChildTwo child )
		{
			// Read->Verify->Write->Commit transaction pattern as
			// alternative to Expected Check Constraints on DeleteItemRequest
			// low-level API call.
			final ChildTwo obj = loadChild(parentHashKey, child.getId());
			if (obj != null) {
				final Lvl6Transaction t1 = repoTxManager.getActiveTransaction();
				if (t1 != null) {
					t1.delete(obj);
				} else {
					// TODO: Just because we read obj in a previous transaction
					// with COMMITTED isolation level does not mean its still in
					// a delete-ready state b/c the transaction used to perform
					// that COMMITTED read has ended by now.
					//
					// We _should_ fail here by now, but lets not. There IS a
					// better solution, in the form a of delete/save helpers on
					// TxManager that launch a temporary transaction and use it
					// to encapsulate a read followed by verify and delete steps
					// _before closing the transaction or returning_.
					//
					// The tough part in that chain is generalizing the
					// validation step between load and save without returning
					// the control flow back to the user by method return. What
					// that tells me is that the validation logic needs be
					// captured in a caller-provided lambda, to be given the
					// result of the load and either accepting or rejecting it
					// as suitable for proceeding with the rest of the delete
					// action.
					mapper.delete(obj);
				}
			}
		}

		@Override
		public void deleteChildren( final String parentHashKey,
		    final Iterable<ChildTwo> childRangeKeys )
		{
			// Read->Verify->Write->Commit transaction pattern as
			// alternative to Expected Check Constraints on DeleteItemRequest
			// low-level API call.
			final List<ChildTwo> objList =
			    loadChildren(parentHashKey, FluentIterable.from(childRangeKeys)
			        .transform(CHILD_TO_ID_FUNCTION));
			final Lvl6Transaction t1 = repoTxManager.getActiveTransaction();
			if (t1 != null) {
				for (final ChildTwo obj : objList) {
					t1.delete(obj);
				}
			} else {
				// TODO: See comment block in deleteChild(). Same applies
				// here too.
				for (final ChildTwo obj : objList) {
					mapper.delete(obj);
				}
			}
		}

		@Override
		public List<ChildTwo> deleteAllChildren( final String parentHashKey )
		{
			// Read->Verify->Write->Commit transaction pattern as
			// alternative to Expected Check Constraints on DeleteItemRequest
			// low-level API call.
			final List<ChildTwo> objList = loadAllChildren(parentHashKey);
			final Lvl6Transaction t1 = repoTxManager.getActiveTransaction();
			if (t1 != null) {
				for (final ChildTwo obj : objList) {
					t1.delete(obj);
				}
			} else {
				// TODO: See comment block in deleteChild(). Same applies
				// here too.
				for (final ChildTwo obj : objList) {
					mapper.delete(obj);
				}
			}

			return objList;
		}

		@Override
		public List<String> removeAllChildren( final String parentHashKey )
		{
			return convertToIds(deleteAllChildren(parentHashKey));
		}

		private String getPartitionedHashKey( final String parentHashKey,
		    final String childRangeKey )
		{
			final int bucket = childRangeKey.hashCode()
			    % numParts;
			return parentHashKey
			    + ':'
			    + bucket;
		}

		private void setPartitionedKey( final String parentHashKey, final ChildTwo obj )
		{
			String childRangeKey = obj.getId();
			if (childRangeKey == null) {
				childRangeKey = UUID.randomUUID()
				    .toString();
				obj.setId(childRangeKey);
			}

			final int bucket = childRangeKey.hashCode()
			    % numParts;
			obj.setUserId(parentHashKey
			    + ':'
			    + bucket);
		}

		private List<String> convertToIds( final Iterable<ChildTwo> objIter )
		{
			final ArrayList<String> retVal = new ArrayList<String>();
			Iterables.addAll(retVal, FluentIterable.from(objIter)
			    .transform(CHILD_TO_ID_FUNCTION));
			return retVal;
		}
	}
}
